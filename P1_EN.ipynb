{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:28<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "class tracker():\n",
    "    \"\"\"\n",
    "    This is a smoothing tracker class to track left/right lanes individually.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # define all local variables\n",
    "        self.m = None\n",
    "        self.b = None\n",
    "        self.ymin = None\n",
    "        self.m_prev = None\n",
    "        self.b_prev = None\n",
    "        self.ymin_prev = None\n",
    "        self.smoothing = (0.75, 0.25)\n",
    "        self.smoothingy = (0.55, 0.45)\n",
    "        self.weights = np.array([0.45, 0.25, 0.15, 0.1, 0.05])\n",
    "\n",
    "\n",
    "        self.marr = np.array([None, None, None, None, None])\n",
    "        self.barr = np.array([None, None, None, None, None])\n",
    "\n",
    "    def update(self,slope,intc,ym):\n",
    "        # circ shift tracking buffer:\n",
    "        self.marr = np.roll(self.marr.copy(),1)\n",
    "        self.barr = np.roll(self.barr.copy(),1)\n",
    "        # updates lane position based on whether lane was detected (simple tracker)\n",
    "        if np.any(np.isnan((slope,intc,ym))):\n",
    "            # no valid input, keep previous estimate...\n",
    "            # shift current measurement to previous, update with smoothing:\n",
    "            self.m_prev = self.m\n",
    "            self.b_prev = self.b\n",
    "            self.marr[0] = self.marr[1]\n",
    "            self.barr[0] = self.barr[1]\n",
    "            self.ymin_prev = self.ymin\n",
    "        else:\n",
    "            # shift current measurement to previous, update with smoothing:\n",
    "            self.m_prev = self.m\n",
    "            self.b_prev = self.b\n",
    "            self.ymin_prev = self.ymin\n",
    "\n",
    "            self.marr[0] = slope\n",
    "            self.barr[0] = intc\n",
    "            # first time initialization\n",
    "            if None in (self.m_prev, self.b_prev, self.ymin_prev):\n",
    "                self.m = slope\n",
    "                self.b = intc\n",
    "                self.ymin = ym\n",
    "\n",
    "            else:\n",
    "                self.m = self.smoothing[0]*slope + self.smoothing[1]*self.m_prev\n",
    "                self.b = self.smoothing[0]*intc  + self.smoothing[1]*self.b_prev\n",
    "                # self.ymin = self.smoothing[0]*ym + self.smoothing[1]*self.ymin_prev\n",
    "                # ALTERNATIVE:\n",
    "                newWeights = self.weights[self.marr!=None]/self.weights[self.marr!=None].sum()\n",
    "                self.m = np.dot(self.marr[self.marr!=None],newWeights)\n",
    "                self.b = np.dot(self.barr[self.marr!=None],newWeights)\n",
    "\n",
    "\n",
    "    def get_points(self,imsize):\n",
    "        # returns start/end points of lane to draw\n",
    "        # calculate the end points using slope y-intercept.\n",
    "        p1 = (int((self.ymin-self.b)/self.m),int(self.ymin))\n",
    "        p2 = (int((imsize[0]-self.b)/self.m),imsize[0])\n",
    "        return p1, p2\n",
    "\n",
    "\n",
    "class lane_detector():\n",
    "    \"\"\"\n",
    "    Lane tracker is an object that tracks both left and right lanes.\n",
    "    It processes images, runs lane detection pipe-line, and makes an estimate as to\n",
    "    which lines correspond to Left/Right lanes.\n",
    "    Lanes are stored as (m,b) line variables with 'soft' tracking enabled such that\n",
    "    position is filtered to ensure smoothness\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.r_lane = tracker()\n",
    "        self.l_lane = tracker()\n",
    "        pass\n",
    "\n",
    "    def grayscale(self,img):\n",
    "        \"\"\"Applies the Grayscale transform\n",
    "        This will return an image with only one color channel\n",
    "        but NOTE: to see the returned image as grayscale\n",
    "        (assuming your grayscaled image is called 'gray')\n",
    "        you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "        # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def canny(self,img, low_threshold, high_threshold):\n",
    "        \"\"\"Applies the Canny transform\"\"\"\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "    def gaussian_blur(self,img, kernel_size):\n",
    "        \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    def normalize_image(self,img):\n",
    "        \"\"\" Normalizes a grayscale image\"\"\"\n",
    "        normalizedImg = np.zeros_like(img)\n",
    "        cv2.normalize(img,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "        return normalizedImg\n",
    "\n",
    "    def region_of_interest(self,img, vertices):\n",
    "        \"\"\"\n",
    "        Applies an image mask.\n",
    "\n",
    "        Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "        \"\"\"\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)\n",
    "\n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "\n",
    "        #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "    def process(self,image):\n",
    "        # apply all preprocessing in one step:\n",
    "        output_image = self.gaussian_blur(self.normalize_image(self.grayscale(image.copy())),7)\n",
    "        # Run Canny Edge detector:\n",
    "        edges = self.canny(output_image, 50, 150)\n",
    "        # Apply image mask:\n",
    "        imshape = image.shape\n",
    "        # arbitrarily set polygon crop region, seems to work\n",
    "        crops = [7.9/16.0, 8.1/16.0, 9/16.0]\n",
    "        vertices = np.array([[(0,imshape[0]),(crops[0]*imshape[1], crops[2]*imshape[0]), (crops[1]*imshape[1], crops[2]*imshape[0]), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        output_image = self.region_of_interest(edges,vertices)\n",
    "        # Get Hough lines:\n",
    "        lines = cv2.HoughLinesP(output_image, 1, np.pi/180, 50, np.array([]), 15, 3)\n",
    "        # now, process lines to get estimate of best fit lanes:\n",
    "        # Color convertion for opencv:\n",
    "        image = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)\n",
    "        line_image = np.zeros_like(image)\n",
    "        try:\n",
    "            self.process_lines(lines)\n",
    "            p1_L, p2_L = self.l_lane.get_points(imshape)\n",
    "            p1_R, p2_R = self.r_lane.get_points(imshape)\n",
    "            cv2.line(line_image, p1_L, p2_L, [255,0,0], 6)\n",
    "            cv2.line(line_image, p1_R, p2_R, [0,255,0], 6)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        alpha_image = cv2.addWeighted(image.copy(), 0.8, line_image, 1.0, 0.)\n",
    "\n",
    "        cv2.imshow(\"test\",alpha_image)\n",
    "        cv2.waitKey(1)\n",
    "        # cv2.destroyAllWindows()\n",
    "        # convert color back:\n",
    "        return cv2.cvtColor(alpha_image.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def process_lines(self,lines):\n",
    "        # for each line in lines, group them by their angle, can make soft assumption that positive slopes will correspond to right lanes, negative slopes - left lanes (since y-coords are flipped)\n",
    "        # upgrade array to float:\n",
    "        flines = lines.astype(float)\n",
    "        linesLocal = flines.copy()\n",
    "        # get slopes:\n",
    "        slopes = np.divide((flines[:,:,3]-flines[:,:,1]),(flines[:,:,2]-flines[:,:,0]))\n",
    "        # get y-intercepts:\n",
    "        intcpt = flines[:,:,1] - np.multiply(slopes,flines[:,:,0])\n",
    "        # get line angles to x-line:\n",
    "        thetas = np.arctan2((flines[:,:,3]-flines[:,:,1]),(flines[:,:,2]-flines[:,:,0]))\n",
    "        # get lines to keep:\n",
    "        keeps = abs(thetas)>30*math.pi/180 # THIS IS IMPORTANT FOR CHALLENGE!\n",
    "        # remove bad data lines:\n",
    "        thetas = thetas[keeps.reshape([keeps.size]),:]\n",
    "        intcpt = intcpt[keeps.reshape([keeps.size]),:]\n",
    "        slopes = slopes[keeps.reshape([keeps.size]),:]\n",
    "        linesLocal = linesLocal[keeps.reshape([keeps.size]),:,:]\n",
    "        # find furthest line point (get min y-value):\n",
    "        ymin = np.array([linesLocal[:,:,1],linesLocal[:,:,3]]).min()\n",
    "        # segment lines into L/R:\n",
    "        left = thetas<0\n",
    "        right = thetas>0\n",
    "        # get average slope & intercept for both sides\n",
    "        l_slope, l_int = self.get_mean_line(slopes[left.reshape([left.size]),:],intcpt[left.reshape([left.size]),:])\n",
    "        r_slope, r_int = self.get_mean_line(slopes[right.reshape([right.size]),:],intcpt[right.reshape([right.size]),:])\n",
    "        # filter to slopes and ints for L/R lanes:\n",
    "        self.r_lane.update(r_slope,r_int,ymin)\n",
    "        self.l_lane.update(l_slope,l_int,ymin)\n",
    "\n",
    "\n",
    "    def get_mean_line(self,slopes=np.empty(1),intercepts=np.empty(1)):\n",
    "        return slopes.mean(), intercepts.mean()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Function handler, loads data, sends to processing.\n",
    "    \"\"\"\n",
    "\n",
    "    # fileName = 'solidWhiteRight.mp4'\n",
    "    fileName = 'solidYellowLeft.mp4'\n",
    "    # fileName = 'challenge.mp4'\n",
    "    white_output = 'test_videos_output/' + fileName\n",
    "    clip1 = VideoFileClip('test_videos/' + fileName)\n",
    "    # make lane tracker object:\n",
    "    detector = lane_detector()\n",
    "    white_clip = clip1.fl_image(detector.process)\n",
    "    white_clip.write_videofile(white_output, audio=False)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
